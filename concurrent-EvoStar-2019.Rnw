\documentclass[runningheads]{llncs}

%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% End:
\usepackage[utf8]{inputenc}
\usepackage{booktabs} % For formal tables
\usepackage{graphicx}


\begin{document}

<<setup, cache=FALSE,echo=FALSE>>=
library(reshape2)
library(ggplot2)
library(ggthemes)

data <- read.csv('individual.csv',header=F)
data.v2 <- melt(data,id.vars=c("V1") )
evaluations <- data.frame(bits=data.v2$V1,evaluations=data.v2$value )

baseline <- read.csv('baseline-ea.csv',header=F,sep=" ")
baseline.v2 <- melt(baseline,id.vars=c("V1"))
baseline.64 <- baseline.v2[baseline.v2$V1==64,]

population <- read.csv('population-concurrency.csv',header=F,sep=" ")
population.v2 <- melt(population,id.vars=c("V1"))
population.64 <- population.v2[population.v2$V1==2,]

comparison.64 <- data.frame(bits=baseline.64$V1,algorithm=rep('Baseline',length(baseline.64$V1)),evaluations=baseline.64$value)
individual.64 <- evaluations[evaluations$bits==64,]

comparison.64 <- rbind(comparison.64,
                       data.frame(bits=population.64$V1,algorithm=rep('Population concurrency',length(population.64$V1)),evaluations=population.64$value))

comparison.64 <- rbind(comparison.64,
                       data.frame(bits=individual.64$bits,algorithm=rep('Individual concurrency',length(individual.64$bits)),evaluations=individual.64$evaluations))

@

\title{Exploring concurrent evolutionary algorithms}
% Juanlu -Consider the title:
% Juanlu -\title{Exploring concurrent and stateless evolutionary algorithms}
% Juanlu - I think missing stateless is missing a good selling point of the paper

% \author{Juan J. Merelo\inst{1}
% \and
% José-Mario García-Valdez\inst{2}}

% \institute{%
%   Universidad de Granada/CITIC\\
%   Granada, Spain\\
%   \email{jmerelo@ugr.es}\\
% \and
% Instituto Tecnológico de Tijuana\\
% Calzada Tecnológico, s/n\\
% Tijuana\\
% Mexico\\
% \email{mario@tectijuana.edu.mx}
% }


\author{A. U. Thorone \inst{1}
\and
A. U. Thortwo \inst{2}}

\institute{%
Institute One\\
\and
Institute Two
}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Creating a concurrent and stateless version of an evolutionary algorithm implies
changes in its behavior. From the performance point of view, the main challenge is to balance computation
with communication, but from the algorithmic point of view we have to
keep diversity high so that the algorithm is not stuck in local
minima. In a concurrent setting, we will have to find the right
balance so that improvements in both fields do not cancel out. This is
what we will be doing in this paper, where we explore the space of
parameters of a population based concurrent evolutionary algorithm to
find out the best combination for a particular problem.
\end{abstract}

\keywords{Concurrent algorithms, distributed computing, stateless algorithms,
algorithm implementation, performance evaluation, distributed computing,
heterogeneous distributed systems.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Concurrent programming adds a layer of abstraction over the parallel
facilities processors and operating systems offer to offer a
high-level interface that allows the user to program code that might
be executed in parallel either in threads or in different processes \cite{andrews1991concurrent}.

Different languages offer different facilities for concurrency at the
primitive level, and mainly differ on how they deal with shared state,
that is, variables that are accessed from several
processes. Actor-based concurrency \cite{schippers2009towards}
eliminates shared state by introducing a series of {\em actors} that
store state and can change it; on the other hand,  channel based
concurrency follows the {\em communicating sequential processes}
methodology \cite{Hoare:1978:CSP:359576.359585}, which is effectively
stateless, with different processes reacting to channel input without
changing state, and writing to these channels. 

This kind of concurrency is the one implemented by many modern
languages such as Go or Perl 6 \cite{lenzperl}. However, the
statelessness of the implementation asks for a change in the
implementation of any algorithm. In particular, evolutionary
algorithms need to change to fit an architecture that creates and
processes streams of data using functions that do not change state. 

%% Juanlu -  This could be a good spot to insert/merge the content of the state of the art (See note in the S.O.A. section)

In previous papers 
\cite{Merelo:2018:MEA:3205651.3208317:anon,Garcia-Valdez:2018:MEA:3205651.3205719:anon},
we presented the proof of concept and initial results with this kind
of stateless evolutionary algorithms, implemented in the Perl 6
language. These evolutionary algorithms use a single channel where
whole populations are sent. The (stateless) functions read a single
population from the channel, run an evolutionary algorithm for a fixed
number of generations, which we call the {\em generation gap} or
simply {\em gap}, and send the population in the final generation back
to the channel. Several populations are created initially, and a
concurrent {\em mixer} is run which takes populations in couples,
mixes them leaving only a single population with the best.
% Juanlu - with the best what? best individuals? Please specify.
% Juanlu - for the future, it would be interesting to study several policies, such as keeping a high diversity instead of just the best individuals. !? 
 This {\em
  gap} is then conceptually, if not functionally, similar to the {\em
  time to migration} in parallel evolutionary algorithms (with which
concurrent evolutionary algorithms have a big resemblance).

We did some initial exploration of the parameter space in
\cite{merelo:WEA:anon}. In these initial explorations we realized
that the parameters we used had an influence at the algorithmic level,
but also at the implementation level, changing the wallclock
performance of the algorithm.

In this paper we will explore the parameter space systematically
looking particularly at two parameters that have a very important
influence on performance: population size and generation gap. Our
intention is to create a rule of thumb for setting them in this kind
of algorithms, so that they are able to achieve the best
performance. 
% Juanlu - If space is needed, the rest of the paragraph is expendable as it will appear in the Experimental Setup section.
In principle, we will work with two threads, one for
mixing the populations and another for evolution. Using more threads
for evolution, in principle, should follow the same rules, but how
that would influence scaling is left for future papers.


The rest of the paper is organized as follows. Next section presents the state
of the art in concurrent and functional programming language  in the
area of parallel evolutionary algorithms. We present two different versions
of a concurrent evolutionary algorithm in Section \ref{sec:impl},
to be followed by actual results in section \ref{sec:res}. Finally, we draw the
conclusions and present future lines of work in section \ref{sec:conclusions}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{State of the Art}
%Juanlu - Think about merging the state of the art at the introduction to save space.

\noindent Despite the emphasis on hardware-based techniques such as
cloud computing or GPGPU, there are not many papers \cite{Xia2010} dealing with
creating concurrent evolutionary algorithms that work in a single
computing node or that extend seamlessly from single to many computers.

For instance, the EvAg model \cite{evag:gpem} is a locally concurrent and globally
parallel evolutionary algorithm that leaves the management of the
different agents (i.e. threads) to the underlying platform scheduler
and displays an interesting feature: the model is able to scale
seamlessly and take full advantage of CPU threads. In a first attempt
to measure the scalability of the approach experiments were conducted
in \cite{wcci:evoag} for a single and a dual-core processor showing
that, for cost functions depassing some milliseconds of computing
time, the model was able to achieve near linear speed-ups . This study
was later on extended in \cite{DBLP:conf/evoW/LaredoBMG12} by scaling
up the experimentation to up to 188 parallel machines. The
reported speed-up was $\times 960$ which is beyond the linear $\times
188$ that could be expected if local concurrency were not taken into
account.  

The aforementioned algorithm used a protocol that worked
asynchronously, leveraging its peer to peer capabilities; in general
the design of concurrent EAs has to take into account the
communication</synchronization 
between processes, which nowadays will be mainly threads. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental setup and results}
\label{sec:res}

The first experiments we have performed for this paper included using
implicit autothreading, in the shape of the method called {\tt race}
or {\tt hyper}. These methods auto-thread the processing of arrays or
list, disregarding the order in the first case, using it in the second
case. In order to check this we implemented the p-peaks function
\cite{kennedy1998matching}, which was considered more adequate for
this task since it is, at the same time, deceptive from the point of
view of the evolutionary algorithm and computing-intensive, involving
computing the distance to a number of generated binary strings, which
in this case were 100.

In order to do this implicitly parallel version, several changes had
to be made to the function that evaluates the whole
population: \begin{itemize}
\item First, the cache had to be turned off. We were using a cache to
  keep all values that were already computed, and we had to stop using
  it. Since it is autothreaded, trying to store or retrieve from the
  cache simultaneously could result in deadlocks or crashes. 
\item Do all the computation in a functional way, without side
  effects. The auto-threaded code must take values, return values,
  without changing any external variable on the fly. All values are
  then computed and assigned to the data structure that holds them.
\end{itemize}

Perl 6, by default, uses 4 threads for auto-threading. We designed
population evaluation so that it was autothreaded, and did some
runtime tests. Without changing the algorithm, this resulted in an
almost 4x speedup of the original code. 

This implies that using implicitly parallel facilities might allow,
without much changes to the underlying algorithm, to use
multithreading and achieve speedups, as already observed in
\cite{DBLP:conf/gecco/GuervosV18}. However, it is essential that what
is being parallelized is a substantial amount of work. Using just
MaxOnes, as in the above mentioned paper, will not offer any
substantial speedups and might even result in performance taking a
hit.


However, we were more interested in creating explicit concurrent
version of the evolutionary algorithm, and do a set of experiments to
make them work properly. In the next set of experiments we will
concentrate not so much in runtime performance, but on algorithmic
performance, that is, the number of evaluations needed to find the
solution.
%
\begin{figure*}[h!tb]
  \centering
<<results-mo, cache=FALSE,echo=FALSE>>=
ggplot(evaluations,aes(x=bits,y=evaluations,group=bits))+geom_boxplot()+ scale_y_log10()+theme_tufte()+labs(x="Bits",y="Evaluations",title="Individually concurrent evolutionary algorithm")
@
\caption{Boxplot of the number of evaluations needed for different number of bits in the MaxOnes problem. Please note that axes $x$ and $y$ both have a logarithmic scale.}
\label{fig:evals:mo}
\end{figure*}
%
In order to perform the experiments, we used Linux boxes (with Ubuntu
14.04 and 16.04), the latest version of the Perl 6 compiler and
virtual machine. First we used a selecto-recombinative evolutionary
algorithm, with no mutation, in order to find out what's the correct
population for every problem size \cite{lobo2005review}. This method
sizes populations looking for the minimal size that achieves a 95\%
success rate on a particular problem and problem size; in this case,
size 512 was the ideal for the MaxOnes problem with size 64. This size
was used as a base for the rest of the problem sizes; since the real
evolutionary algorithm actually uses mutation, the population was
halved for the actual experiments. This population size is more
dependent on the problem itself than on the particular implementation,
that is why we use it for all implementations.
%
\begin{figure}[h!tb]
  \centering
<<population-initial, cache=FALSE,echo=FALSE>>=
population.initial <- data.frame(Number=population.v2$V1,Evaluations=population.v2$value)
ggplot(population.initial,aes(x=Number,y=Evaluations,group=Number))+geom_boxplot()+theme_tufte()+labs(x="Number of initial populations",y="Evaluations",title="Comparing population-level concurrent EA for different number of initial populations")+ scale_y_log10()
@
\caption{Boxplot comparing the number of evaluations needed for solving the 64 bit onemax problem using the population-level concurrent algorithm with different number of initial populations.}
\label{fig:pop:initial}
\end{figure}
%
%
\begin{figure}[h!tb]
  \centering
<<comparison-mo, cache=FALSE,echo=FALSE>>=
ggplot(comparison.64,aes(x=algorithm,y=evaluations,group=algorithm))+geom_boxplot()+theme_tufte()+labs(x="Algorithm",y="Evaluations",title="Comparing algorithms for the 64 bit onemax problem")+ scale_y_log10()
@
\caption{Boxplot comparing the number of evaluations needed for solving the 64 bit onemax problem in the individually concurrent and canonical EA version.}
\label{fig:comparison}
\end{figure}
%
First we run a basic evolutionary algorithm with different chromosome
sizes, to get a baseline of the number of evaluations needed for
finding the solution in that case. Time needed was the main requisite
for choosing the different sizes, although we think that scaling
should follow more or less the same trend as shown for smaller
sizes. We compared mainly the number of evaluations needed, since that
is the main measure of the quality of the algorithm.

We show in Figure \ref{fig:evals:mo} the logarithmic chart  of the
number of evaluations needed to find the solution for different, logarithmically
growing, chromosome sizes using the individually concurrent
evolutionary algorithm. There is a logical increase in the number of
evaluations needed, but the fact that it is a low number and its
scaling prove that this simple concurrent implementation is indeed an
evolutionary algorithm, and does not get stuck in diversity traps that
take it to local minimum. The number of evaluations is, in fact, quite
stable.

We did the same for the population-level concurrent algorithm;
however, since this one has got parameters to tune, we had to find a
good result. In order to do that, we tested different number of
initial populations placed in the channel, since this seems to be the
critical parameter, more than the number of generations until
mixing. The results are shown in Figure \ref{fig:pop:initial}. The
difference between using 4 and 6 initial populations is virtually
none, but there is a slight advantage if you use only 2 initial
populations to kickstart the channel. Please bear in mind that, in
this case, the concept of {\em population} is slightly different from
the one used in island EAs. While in the latter the population does
not move from the island, in this case populations are read from
channels and acted upon, and in principle there could be as many
initial or unread populations as wanted or needed; every function in
every thread will process a single population nonetheless. 

We can now compare these two algorithms with the baseline EA. This is
a canonical evolutionary algorithm using bitflip mutation and
two-point crossover, using roulette wheel as a selection method. It
has, as the rest of the implementations of the algorithms, been
implemented using {\tt Algorithm::Evolutionary::Simple}, the free
software module in Perl 6.

The comparison is shown in Figure
\ref{fig:comparison}, which shows, in a logarithmic $y$ scale, a
boxplot of the number of evaluations for the baseline, as well as the
two different concurrent algorithms, at the population and individual
level. As it can be seen, this last algorithm outperforms the other
two, achieving the same result using many less evaluations, almost one
order of magnitude less. In fact, both concurrent algorithms are
better than the baseline, and please note this measures the number of
evaluations, equivalent to the algorithmic complexity, and not
time. This figure is the base to reach our conclusions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and discussion}
\label{sec:conclusions}

It is natural to take advantage of the multi-threading and multi-process
capabilities of modern hardware architectures to make evolutionary or other
population-based algorithms run faster by using all CPUs and threads
at the same time; that can be done in a very
straightforward way by parallelizing the evolutionary algorithm using
the many available models, such as island model; however, it is
possible that adapting the algorithm itself to the architecture makes
its performance better, by actually adapting the resources consumed to
the resources used, instead of allocating them in advance as it is
done in island architectures.

The first exploration of the facilities for concurrent programming
Perl 6 uses has been done through the auto-threading mechanism that
allows the parallel execution of code on arrays or lists. After making
small changes, this resulted in a speedup of the program in a number
that is compatible with the number of threads used by default, four.

However, a change to a concurrent architecture implies looking at an
algorithm in a different, non sequential way, 
that is why the first thing that has to be evaluated is the actual
number of evaluations that need to be done to solve the problem, since
the new implementation is not functionally equivalent to the old one. This
is what we have done in this paper. We have proposed two different
concurrent implementations of an evolutionary algorithms with different
{\em grain}: a {\em fine-grained} one that acts at the individual
level, and a {\em coarse-grained} one that acts at the level of populations.

The individual-level concurrent EA shows a good scaling across problem
size; besides, when comparing it with the population-level concurrent
EA and the canonical and sequential evolutionary algorithm, it obtains
a much better performance, being able to obtain the solution with a
much lower evaluation budget. Second best is the population-level
concurrent algorithm, to be followed by the baseline canonical EA,
which obtains the worse result. This proves that, even from the purely
algorithmic point of view, concurrent evolutionary algorithms are
better than sequential algorithms. If we consider time, the difference
increases, since the only sequential part of the concurrent algorithms
is reading from the channels, but once reading has been done the rest
of the operations can be performed concurrently, not to mention every
function can have as many copies as needed running in different
threads.

These results are not so much inherent to the concurrency itself as
dependent on the selection operators that have been included in the
concurrent version of the algorithms. The selection pressure of the
canonical algorithm is relatively low, depending on the roulette wheel
selection algorithm, as opposed to the more greedy operation of the
individual-level algorith, which uses tournament selection. The
population-level concurrent algorithm eliminates half the population
with the worst fitness, although every generation it is running a
canonical EA identical to the baseline; however, this exerts a high
selective pressure on the population which, combined with the
increased diversity of running two populations in parallel, results in
better performance. Same happens with the individual-level concurrent EA:
the worst of three is always eliminated, which exerts a big pressure
on the population, which is thus able to find the solution much
faster. Nothing prevents us from using these same mechanisms in an
evolutionary algorithm, which would then be functionally equivalent to
these concurrent algorithms, but we wanted to compare a canonical EA
to {\em canonical} concurrent evolutionary algorithms, at the same
time we compare different versions of them; in this sense, it is
better to use this individual-level concurrent algorithm in future
versions of the evolutionary algorithm library.

The main conclusion of this paper is that evolutionary algorithms can
benefit from concurrent implementations, and that these should be as
fine grained as possible. However, a lot of work remains to be
done. One line of research will be to try and use the implicitly
concurrent capabilities of Perl 6 to perform multi-threaded evaluation
or any other part of the algorithm, which would delegate the use of
the threading facilities to the compiler and virtual machine. That
will have no implications on the number of evaluations, but will help
make the overall application faster.

Of course, time comparisons will also have to be made, as well as a
more thorough exploration of the parameter space of the
population-level evolutionary algorithm. Since this type of algorithm
has a lower overhead, communicating via channels with lower frequency,
it could be faster than the individual-level concurrent EA. Measuring
the scaling with the number of thread is also an interesting line to
pursue; since our architecture is using single channels, this might
eventually be a bottleneck, and will prevent scaling to an indefinite
number of threads. However, that number might be higher than the
available number of threads in a desktop processor, so it has to be
measured in practice.

This paper has been intended mainly as a proof of concept, and thus
does not really focuses on creating a scalable architecture for
concurrent evolutionary algorithms. Preliminary results with the
individual-level concurrency indicate that a basic redesign is
probably needed to achieve good scaling performance. One of the
problems with this architecture is that actually every thread is doing
much less work than communication; since the application is
communication-bound it will get worse as the number of threads
increases. While keeping functional equivalence, it is probably better
to work with bigger batch sizes instead of working with a single
individual. 

Finally, we would like to remark that this paper is part of the open
science effort by the authors. It is hosted in GitHub, and the paper
repository hosts the data and scripts used to process them, which are
in fact embedded in this paper source code using Knitr \cite{xie2013knitr}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

%%   This paper has been supported in part by
%% projects TIN2014-56494-C4-3-P s (Spanish Ministry of Economy and
%% Competitiveness) and DeepBio (TIN2017-85727-C4-2-P). I would like to
%% express my gratefulness to the users in the \#perl6 IRC channel,
%% specially Elizabeth Mattijsen, Timo Paulsen and Zoffix Znet, who
%% helped me with the adventure of programming efficient concurrent
%% evolutionary algorithms. 
Acknowledgements taking\\
this much\\
space

\bibliographystyle{splncs04}
\bibliography{geneura,concurrent,perl6}

\end{document}
