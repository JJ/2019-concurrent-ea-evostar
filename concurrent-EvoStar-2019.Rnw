\documentclass[runningheads]{llncs}

%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% End:
\usepackage[utf8]{inputenc}
\usepackage{booktabs} % For formal tables
\usepackage{graphicx}


\begin{document}

<<setup, cache=FALSE,echo=FALSE>>=
library(ggplot2)
library(ggthemes)

data <- read.csv("data/evostar2019.csv")
data$gap = as.factor(data$gap)
@

\title{Exploring concurrent and stateless evolutionary algorithms}

% \author{Juan J. Merelo\inst{1}
% \and
% José-Mario García-Valdez\inst{2}}

% \institute{%
%   Universidad de Granada/CITIC\\
%   Granada, Spain\\
%   \email{jmerelo@ugr.es}\\
% \and
% Instituto Tecnológico de Tijuana\\
% Calzada Tecnológico, s/n\\
% Tijuana\\
% Mexico\\
% \email{mario@tectijuana.edu.mx}
% }


\author{A. U. Thorone \inst{1}
\and
A. U. Thortwo \inst{2}}

\institute{%
Institute One\\
\and
Institute Two
}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Creating a concurrent and stateless version of an evolutionary algorithm implies
changes in its behavior. From the performance point of view, the main challenge is to balance computation
with communication, but from the algorithmic point of view we have to
keep diversity high so that the algorithm is not stuck in local
minima. In a concurrent setting, we will have to find the right
balance so that improvements in both fields do not cancel out. This is
what we will be doing in this paper, where we explore the space of
parameters of a population based concurrent evolutionary algorithm to
find out the best combination for a particular problem.
\end{abstract}

\keywords{Concurrent algorithms, distributed computing, stateless algorithms,
algorithm implementation, performance evaluation, distributed computing,
heterogeneous distributed systems.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Concurrent programming adds a layer of abstraction over the parallel
facilities processors and operating systems offer to offer a
high-level interface that allows the user to program code that might
be executed in parallel either in threads or in different processes \cite{andrews1991concurrent}.

Different languages offer different facilities for concurrency at the
primitive level, and mainly differ on how they deal with shared state,
that is, variables that are accessed from several
processes. Actor-based concurrency \cite{schippers2009towards}
eliminates shared state by introducing a series of {\em actors} that
store state and can change it; on the other hand,  channel based
concurrency follows the {\em communicating sequential processes}
methodology \cite{Hoare:1978:CSP:359576.359585}, which is effectively
stateless, with different processes reacting to channel input without
changing state, and writing to these channels. 

This kind of concurrency is the one implemented by many modern
languages such as Go or Perl 6 \cite{lenzperl}. However, the
statelessness of the implementation asks for a change in the
implementation of any algorithm. In particular, evolutionary
algorithms need to change to fit an architecture that creates and
processes streams of data using functions that do not change state. 

\noindent Despite the emphasis on hardware-based techniques such as
cloud computing or GPGPU, there are not many papers \cite{Xia2010} dealing with
creating concurrent evolutionary algorithms that work in a single
computing node or that extend seamlessly from single to many computers.

For instance, the EvAg model \cite{evag:gpem} is a locally concurrent and globally
parallel evolutionary algorithm that leaves the management of the
different agents (i.e. threads) to the underlying platform scheduler
and displays an interesting feature: the model is able to scale
seamlessly and take full advantage of CPU threads. In a first attempt
to measure the scalability of the approach experiments were conducted
in \cite{wcci:evoag} for a single and a dual-core processor showing
that, for cost functions depassing some milliseconds of computing
time, the model was able to achieve near linear speed-ups . This study
was later on extended in \cite{DBLP:conf/evoW/LaredoBMG12} by scaling
up the experimentation to up to 188 parallel machines. The
reported speed-up was $\times 960$ which is beyond the linear $\times
188$ that could be expected if local concurrency were not taken into
account.  

The aforementioned algorithm used a protocol that worked
asynchronously, leveraging its peer to peer capabilities; in general
the design of concurrent EAs has to take into account the
communication</synchronization 
between processes, which nowadays will be mainly threads. Although the
paper above was original in its approach, other authors targeted
explicitly multi-core architectures, such as Tagawa
\cite{Tagawa201212} which used shared memory and a clever mechanism to
avoid deadlock. Other authors \cite{kerdprasop2012concurrent} actually
use a message-based architecture based in the concurrent functional
language Erlang, which separates GA populations as different
processes, although all communication takes place with a common
central thread. 

In our previous papers 
\cite{Merelo:2018:MEA:3205651.3208317:anon,Garcia-Valdez:2018:MEA:3205651.3205719:anon},
we presented the proof of concept and initial results with this kind
of stateless evolutionary algorithms, implemented in the Perl 6
language. These evolutionary algorithms use a single channel where
whole populations are sent. The (stateless) functions read a single
population from the channel, run an evolutionary algorithm for a fixed
number of generations, which we call the {\em generation gap} or
simply {\em gap}, and send the population in the final generation back
to the channel. Several populations are created initially, and a
concurrent {\em mixer} is run which takes populations in couples,
mixes them leaving only a single population with the best individuals
selected from the two merged populations.
% Juanlu - for the future, it would be interesting to study several policies, such as keeping a high diversity instead of just the best individuals. !? 
% Please write an issue so that we don't forget - JJ
 This {\em
  gap} is then conceptually, if not functionally, similar to the {\em
  time to migration} in parallel evolutionary algorithms (with which
concurrent evolutionary algorithms have a big resemblance).

We did some initial exploration of the parameter space in
\cite{merelo:WEA:anon}. In these initial explorations we realized
that the parameters we used had an influence at the algorithmic level,
but also at the implementation level, changing the wallclock
performance of the algorithm.

In this paper we will explore the parameter space systematically
looking particularly at two parameters that have a very important
influence on performance: population size and generation gap. Our
intention is to create a rule of thumb for setting them in this kind
of algorithms, so that they are able to achieve the best
performance. 
% Juanlu - If space is needed, the rest of the paragraph is expendable as it will appear in the Experimental Setup section.


We will present the experimental setup next.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental setup and results}
\label{sec:res}

In principle, we will work with two threads, one for
mixing the populations and another for evolution. Using more threads
for evolution, in principle, should follow the same rules, but how
that would influence scaling is left for future papers.

What we wanted to find out in these set of experiments is what is the
generation gap that gives the best performance in terms of raw time to
find to solution, as well as the best number of evaluations per
second. In order to do that, we prepared an experiment using the
OneMax function with 64 bits, a concurrent evolutionary algorithm such
as the one described in \cite{Merelo:2018:MEA:3205651.3208317:anon},
which is based in the free Perl 6 evolutionary algorithm library {\tt
  Algorithm::Evolutionary::Simple}, and run the experiments in a
machine with Ubuntu 18.04, an AMD Ryzen 7 2700X Eight-Core Processor
at 2195MHz. The Rakudo version was 6.d, which had recently been
released with many improvements to the concurrent core of the
language. All scripts, as well as processing scripts and data obtained
in the experiments is available, under a free license, from our GitHub
repository.


%
\begin{figure*}[h!tb]
  \centering
<<results-evals,cache=FALSE,echo=FALSE>>=
ggplot(data,aes(x=evaluations,y=time,color=gap))+scale_color_brewer(palette="Set1")+geom_point(size=3,aes(shape=gap))+theme_tufte()+labs(x="Evaluations",y="Time",title="Evaluations vs Time per generation gap")
@
\caption{Number of evaluations needed vs. time needed for them for
  different generation gaps, from 8 to 64 }
\label{fig:evals}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section{Conclusions and discussion}
\label{sec:conclusions}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

%%   This paper has been supported in part by
%% projects TIN2014-56494-C4-3-P s (Spanish Ministry of Economy and
%% Competitiveness) and DeepBio (TIN2017-85727-C4-2-P). I would like to
%% express my gratefulness to the users in the \#perl6 IRC channel,
%% specially Elizabeth Mattijsen, Timo Paulsen and Zoffix Znet, who
%% helped me with the adventure of programming efficient concurrent
%% evolutionary algorithms. 
Acknowledgements taking\\
this much\\
space

\bibliographystyle{splncs04}
\bibliography{geneura,concurrent,perl6}

\end{document}
